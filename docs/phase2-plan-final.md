# План реализации Этапа 2: Базовая индексация

## Цели этапа

- Разработка системы разбиения текста на чанки с различными стратегиями
- Реализация генерации эмбеддингов из текстовых чанков с поддержкой разных моделей
- Настройка Qdrant для хранения и поиска векторных представлений
- Создание базового семантического поиска с фильтрацией по метаданным
- Интеграция компонентов в единый конвейер обработки текста

## Детальные задачи и требования

### 1. Расширение схемы базы данных для чанков

**Задача**: Расширить схему SQLite для поддержки хранения информации о чанках и их эмбеддингах.

**Требования**:
- Добавление новых таблиц для хранения информации о чанках
- Создание связей между чанками и оригинальными документами
- Поддержка хранения метаданных об эмбеддингах
- Оптимизация схемы для эффективных запросов
- Подготовка миграций для обновления существующей базы данных

**Детальная схема расширений**:

```
# Таблица чанков
chunks:
  id: INTEGER PRIMARY KEY
  file_id: INTEGER FOREIGN KEY       # Ссылка на файл
  content_id: INTEGER FOREIGN KEY    # Ссылка на извлеченный контент
  chunk_index: INTEGER               # Позиция чанка в документе
  text: TEXT                         # Текст чанка
  chunk_hash: TEXT                   # Хеш содержимого чанка
  start_offset: INTEGER              # Позиция начала в оригинальном тексте
  end_offset: INTEGER                # Позиция конца в оригинальном тексте
  page_num: INTEGER                  # Номер страницы (для PDF)
  language: TEXT                     # Язык текста в чанке
  created_at: TIMESTAMP              # Время создания чанка
  
# Таблица эмбеддингов
embeddings:
  id: INTEGER PRIMARY KEY
  chunk_id: INTEGER FOREIGN KEY      # Ссылка на чанк
  model_id: INTEGER FOREIGN KEY      # Ссылка на модель эмбеддинга
  vector_id: TEXT                    # ID в Qdrant
  created_at: TIMESTAMP              # Время создания эмбеддинга
  
# Таблица моделей эмбеддингов
embedding_models:
  id: INTEGER PRIMARY KEY
  name: TEXT                         # Название модели
  version: TEXT                      # Версия модели
  dimensions: INTEGER                # Размерность векторов
  language_support: TEXT             # Поддерживаемые языки
  is_active: BOOLEAN                 # Активна ли модель
  created_at: TIMESTAMP              # Время добавления
```

### 2. Разбиение текста на чанки

**Задача**: Разработать модуль для разбиения извлеченного текста на логические фрагменты (чанки) различными способами.

**Требования**:
- Реализация нескольких стратегий разбиения:
  - **По размеру**: фиксированное количество токенов/символов
  - **По семантическим границам**: предложения, параграфы
  - **По структурным границам**: заголовки, разделы, списки (если присутствуют в структуре)
  - **Комбинированный подход**: учет семантики с ограничением по размеру
- Настраиваемые параметры для каждой стратегии:
  - Максимальный/минимальный размер чанка
  - Размер перекрытия между соседними чанками
  - Приоритет сохранения смысловых единиц
- Сохранение информации о позиции чанка в оригинальном документе (смещение, страница)
- Выбор оптимальной стратегии в зависимости от типа документа и его структуры
- Определение языка на уровне чанка для лучшей обработки многоязычных документов
- Хеширование чанков для выявления дубликатов

**Архитектура**:
- Базовый абстрактный класс `ChunkStrategy` с общим интерфейсом
- Конкретные реализации для разных стратегий разбиения
- Фабрика стратегий для выбора подходящего метода
- Пайплайн обработки с возможностью комбинирования стратегий

**Используемые библиотеки**:
- `llama-index` (text_splitter) или `langchain` (RecursiveCharacterTextSplitter) - базовые сплиттеры
- `nltk` или `spacy` - для токенизации и определения границ предложений/параграфов
- `langid` или `fasttext` - для определения языка на уровне чанка

### 3. Генерация эмбеддингов

**Задача**: Разработать модуль для создания векторных представлений (эмбеддингов) текстовых чанков.

**Требования**:
- Создание абстракции для работы с различными моделями эмбеддингов
- Поддержка локальных моделей для независимости от внешних API:
  - Многоязычные модели для поддержки русского и английского текстов
  - Модели разного размера (балансирование качества и производительности)
- Пакетная обработка для повышения производительности
- Кэширование эмбеддингов для оптимизации при повторных запусках
- Отслеживание версий моделей для возможности переиндексации
- Нормализация входных данных для улучшения качества эмбеддингов
- Обработка ошибок и повторные попытки при сбоях

**Архитектура**:
- Абстрактный интерфейс `EmbeddingModel` для унификации доступа к моделям
- Конкретные реализации для разных библиотек/моделей
- Менеджер моделей для управления жизненным циклом и версиями
- Сервис эмбеддингов с поддержкой пакетной обработки и кэширования

**Используемые библиотеки**:
- `sentence-transformers` - основная библиотека для эмбеддинг-моделей
- Рекомендуемые модели:
  - `paraphrase-multilingual-mpnet-base-v2` - универсальная многоязычная модель
  - `all-MiniLM-L6-v2` - легкая модель для высокой производительности
  - `intfloat/multilingual-e5-large` - качественная многоязычная модель (при наличии ресурсов)
- Опционально: `fastembed` - для оптимизации производительности на CPU

### 4. Настройка Qdrant и интеграция

**Задача**: Настроить векторную базу данных Qdrant и разработать интерфейс для взаимодействия с ней.

**Требования**:
- Установка и конфигурация Qdrant (локально или в Docker)
- Создание и настройка коллекций с оптимальными параметрами:
  - Выбор метрики расстояния (cosine, dot, euclidean)
  - Настройка HNSW параметров для баланса точности и производительности
  - Определение оптимальной структуры payload для метаданных
- Разработка интерфейса для операций:
  - Создание коллекций с нужной конфигурацией
  - Добавление/обновление/удаление векторов и метаданных
  - Поиск ближайших соседей с возможностью фильтрации
  - Пакетные операции для оптимизации производительности
- Синхронизация с SQLite для обеспечения целостности данных
- Мониторинг состояния и производительности Qdrant
- Настройка резервного копирования коллекций

**Архитектура**:
- Класс-оболочка над `qdrant_client` для унификации взаимодействия
- Сервис для управления коллекциями и их конфигурациями
- Репозиторий для абстракции операций CRUD с векторами
- Интерфейс для поиска с различными параметрами

**Используемые инструменты**:
- `qdrant-client` - официальный Python-клиент для Qdrant
- Docker - для контейнеризации Qdrant
- REST API Qdrant - для административных операций

### 5. Семантический поиск

**Задача**: Разработать модуль для семантического поиска в проиндексированных документах с фильтрацией по метаданным.

**Требования**:
- Создание интерфейса поиска с поддержкой:
  - Текстовых запросов на естественном языке
  - Фильтрации по метаданным (тип файла, дата, язык и т.д.)
  - Настройки параметров поиска (количество результатов, порог сходства)
- Преобразование запросов в эмбеддинги с использованием той же модели
- Поиск ближайших соседей в Qdrant с применением фильтров
- Ранжирование результатов по релевантности
- Обогащение результатов контекстом (извлечение соответствующих фрагментов)
- Объединение похожих результатов для уменьшения дублирования
- Оптимизация запросов для быстрого отклика

**Архитектура**:
- Сервис поиска с поддержкой различных типов запросов
- Преобразователь запросов в эмбеддинги
- Система фильтрации на основе метаданных
- Компоненты обогащения и ранжирования результатов

**Используемые компоненты**:
- Модули эмбеддингов из предыдущих задач
- Qdrant API для поиска
- SQLite для получения дополнительной информации о документах

### 6. Интеграция компонентов

**Задача**: Интегрировать все разработанные компоненты в единый конвейер обработки и поиска.

**Требования**:
- Создание пайплайна индексации:
  - Чтение извлеченного текста из SQLite
  - Разбиение на чанки
  - Генерация эмбеддингов
  - Сохранение в Qdrant и SQLite
- Разработка системы инкрементальных обновлений:
  - Обнаружение измененных файлов
  - Удаление устаревших данных (чанки, эмбеддинги)
  - Обновление только нужных компонентов
- Создание API для интеграции с CLI и будущим веб-интерфейсом
- Оптимизация производительности всего пайплайна
- Настройка системы логирования и мониторинга
- Разработка механизмов обработки ошибок и восстановления

**Архитектура**:
- Фасадный сервис для координации компонентов
- Система заданий и очередей для асинхронной обработки
- Наблюдатель за изменениями для инкрементальных обновлений
- API-слой для внешнего взаимодействия

## План реализации

### Неделя 1: Расширение базы данных и разбиение на чанки (7-10 дней)

1. **День 1-3**: Проектирование и расширение схемы базы данных
   - Создание новых таблиц для чанков и эмбеддингов
   - Разработка миграций для обновления существующей базы
   - Реализация моделей SQLAlchemy для новых таблиц
   - Тестирование операций CRUD

2. **День 4-7**: Разработка стратегий разбиения текста
   - Создание базовой архитектуры для стратегий чанкинга
   - Реализация разбиения по размеру (символы/токены)
   - Реализация разбиения по семантическим границам
   - Реализация комбинированных стратегий
   - Сохранение информации о позиции чанков

3. **День 8-10**: Тестирование и оптимизация чанкинга
   - Тестирование на различных типах документов
   - Определение оптимальных параметров для разных типов
   - Интеграция определения языка
   - Документирование компонента

### Неделя 2: Эмбеддинги и настройка Qdrant (7-10 дней)

1. **День 1-4**: Разработка модуля эмбеддингов
   - Создание абстракции для моделей эмбеддингов
   - Интеграция sentence-transformers
   - Реализация пакетной обработки
   - Создание системы кэширования
   - Механизм управления версиями моделей

2. **День 5-10**: Настройка Qdrant и интеграция
   - Установка и конфигурация Qdrant
   - Разработка сервиса для работы с Qdrant
   - Реализация основных операций (создание коллекций, добавление, поиск)
   - Интеграция с модулем эмбеддингов
   - Синхронизация с SQLite
   - Тестирование на небольших наборах данных

### Неделя 3: Семантический поиск и интеграция (7-9 дней)

1. **День 1-4**: Разработка модуля семантического поиска
   - Создание интерфейса поиска
   - Реализация преобразования запросов
   - Разработка системы фильтрации
   - Обработка результатов и их обогащение
   - Тестирование на индексированных документах

2. **День 5-9**: Интеграция компонентов
   - Создание единого пайплайна индексации
   - Разработка системы инкрементальных обновлений
   - Создание API для внешнего взаимодействия
   - Расширение CLI для новых функций
   - Оптимизация производительности

### Неделя 4: Тестирование, оптимизация и документация (6-8 дней)

1. **День 1-3**: Комплексное тестирование
   - Тестирование на большом наборе данных
   - Выявление и исправление ошибок
   - Оптимизация производительности
   - Стресс-тестирование компонентов

2. **День 4-6**: Оптимизация и улучшения
   - Оптимизация использования памяти
   - Улучшение производительности критических компонентов
   - Реализация дополнительных функций
   - Повышение надежности системы

3. **День 7-8**: Документация и переход к следующему этапу
   - Завершение документации
   - Подготовка к Этапу 3
   - Обзор проделанной работы
   - Определение приоритетов для следующего этапа

## Ожидаемые результаты

По завершении Этапа 2 мы получим:

1. Расширенную базу данных с поддержкой чанков и эмбеддингов
2. Гибкую систему разбиения текста с различными стратегиями
3. Модуль для генерации эмбеддингов с поддержкой разных моделей
4. Настроенную векторную базу данных Qdrant с оптимальными параметрами
5. Функциональный семантический поиск с фильтрацией
6. Интегрированный пайплайн обработки и поиска

Эти компоненты создадут основу для расширенного анализа содержимого на следующих этапах.

## Метрики успеха

- **Чанкинг**: корректное разбиение >95% поддерживаемых документов с сохранением смысловых границ
- **Эмбеддинги**: генерация векторов со скоростью >30 чанков/сек на CPU
- **Qdrant**: время запроса <100 мс для коллекции до 100,000 векторов
- **Поиск**: релевантные результаты в топ-5 для >90% тестовых запросов
- **Пайплайн**: полный процесс индексации текста 1 МБ за <30 сек

## Потенциальные риски и их минимизация

- **Производительность эмбеддингов**: балансировка размера моделей и качества, оптимизация пакетной обработки
- **Масштабируемость Qdrant**: мониторинг использования ресурсов, настройка параметров HNSW
- **Качество чанкинга**: тщательное тестирование на разных типах документов, комбинирование стратегий
- **Интеграция компонентов**: модульное тестирование, четкие интерфейсы между модулями
- **Инкрементальные обновления**: продуманная стратегия удаления и обновления связанных данных
